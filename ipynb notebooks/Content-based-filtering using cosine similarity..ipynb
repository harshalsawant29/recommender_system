{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f27ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf55489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>title_y</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>category_Grocery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>fresh tasting smelling slightly acidic light l...</td>\n",
       "      <td>happen instant pod dual coffee maker spots nes...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>5</td>\n",
       "      <td>dynamic flavor interesting flavor profile body...</td>\n",
       "      <td>tried leggero light roast lungo medium roast d...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>pricey much flavor</td>\n",
       "      <td>great roast ppl arent bitter heavy taste like ...</td>\n",
       "      <td>AEUDZQDVSZYCHEXQSXLB6NWQTMHA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>fun</td>\n",
       "      <td>much fun color cookies artist really work well...</td>\n",
       "      <td>AGECC4F4CDL2AVODIRNCF3V63BEQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect touch</td>\n",
       "      <td>perfect adding creative touches taste coloring...</td>\n",
       "      <td>AFF6LERKD46F2RLIKAMQTAQPOIWA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_x  average_rating   \n",
       "0  instant compostable espresso capsules lungo me...             4.3  \\\n",
       "1  instant compostable espresso capsules lungo me...             4.3   \n",
       "2  instant compostable espresso capsules lungo me...             4.3   \n",
       "3  edible markersfood coloring markersfood colori...             4.3   \n",
       "4  edible markersfood coloring markersfood colori...             4.3   \n",
       "\n",
       "   rating_number  price parent_asin  rating   \n",
       "0             85   8.49  B0C2W77WJX       4  \\\n",
       "1             85   8.49  B0C2W77WJX       5   \n",
       "2             85   8.49  B0C2W77WJX       4   \n",
       "3           1193   8.99  B07PK9L29R       5   \n",
       "4           1193   8.99  B07PK9L29R       5   \n",
       "\n",
       "                                             title_y   \n",
       "0  fresh tasting smelling slightly acidic light l...  \\\n",
       "1  dynamic flavor interesting flavor profile body...   \n",
       "2                                 pricey much flavor   \n",
       "3                                                fun   \n",
       "4                                      perfect touch   \n",
       "\n",
       "                                                text   \n",
       "0  happen instant pod dual coffee maker spots nes...  \\\n",
       "1  tried leggero light roast lungo medium roast d...   \n",
       "2  great roast ppl arent bitter heavy taste like ...   \n",
       "3  much fun color cookies artist really work well...   \n",
       "4  perfect adding creative touches taste coloring...   \n",
       "\n",
       "                        user_id  category_Grocery  \n",
       "0  AF2BLE54TEMGZ546U763ZHZRXC4A                 1  \n",
       "1  AF2BLE54TEMGZ546U763ZHZRXC4A                 1  \n",
       "2  AEUDZQDVSZYCHEXQSXLB6NWQTMHA                 1  \n",
       "3  AGECC4F4CDL2AVODIRNCF3V63BEQ                 1  \n",
       "4  AFF6LERKD46F2RLIKAMQTAQPOIWA                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"model_building.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b91e226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110596, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf32db-f4d6-4af9-9f68-439aab6615dd",
   "metadata": {},
   "source": [
    "## Data Preprocessing: Tokenization\n",
    "### Objective: Convert text data into tokens for further analysis.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "- Import Libraries: Utilize nltk for natural language processing tasks.\n",
    "- Download Necessary Resources: Ensure the ‘punkt’ tokenizer models are available.\n",
    "- Data Conversion: Cast the ‘text’ column to string type to avoid type-related errors.\n",
    "- Tokenization: Apply word_tokenize from nltk to split the text into individual words or tokens.\n",
    "- Store Tokens: Save the tokenized data in a new column ‘tokenized_reviews’ for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d29ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hrishikesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>title_y</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>category_Grocery</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>fresh tasting smelling slightly acidic light l...</td>\n",
       "      <td>happen instant pod dual coffee maker spots nes...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "      <td>[happen, instant, pod, dual, coffee, maker, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>5</td>\n",
       "      <td>dynamic flavor interesting flavor profile body...</td>\n",
       "      <td>tried leggero light roast lungo medium roast d...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "      <td>[tried, leggero, light, roast, lungo, medium, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>pricey much flavor</td>\n",
       "      <td>great roast ppl arent bitter heavy taste like ...</td>\n",
       "      <td>AEUDZQDVSZYCHEXQSXLB6NWQTMHA</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, roast, ppl, arent, bitter, heavy, tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>fun</td>\n",
       "      <td>much fun color cookies artist really work well...</td>\n",
       "      <td>AGECC4F4CDL2AVODIRNCF3V63BEQ</td>\n",
       "      <td>1</td>\n",
       "      <td>[much, fun, color, cookies, artist, really, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect touch</td>\n",
       "      <td>perfect adding creative touches taste coloring...</td>\n",
       "      <td>AFF6LERKD46F2RLIKAMQTAQPOIWA</td>\n",
       "      <td>1</td>\n",
       "      <td>[perfect, adding, creative, touches, taste, co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_x  average_rating   \n",
       "0  instant compostable espresso capsules lungo me...             4.3  \\\n",
       "1  instant compostable espresso capsules lungo me...             4.3   \n",
       "2  instant compostable espresso capsules lungo me...             4.3   \n",
       "3  edible markersfood coloring markersfood colori...             4.3   \n",
       "4  edible markersfood coloring markersfood colori...             4.3   \n",
       "\n",
       "   rating_number  price parent_asin  rating   \n",
       "0             85   8.49  B0C2W77WJX       4  \\\n",
       "1             85   8.49  B0C2W77WJX       5   \n",
       "2             85   8.49  B0C2W77WJX       4   \n",
       "3           1193   8.99  B07PK9L29R       5   \n",
       "4           1193   8.99  B07PK9L29R       5   \n",
       "\n",
       "                                             title_y   \n",
       "0  fresh tasting smelling slightly acidic light l...  \\\n",
       "1  dynamic flavor interesting flavor profile body...   \n",
       "2                                 pricey much flavor   \n",
       "3                                                fun   \n",
       "4                                      perfect touch   \n",
       "\n",
       "                                                text   \n",
       "0  happen instant pod dual coffee maker spots nes...  \\\n",
       "1  tried leggero light roast lungo medium roast d...   \n",
       "2  great roast ppl arent bitter heavy taste like ...   \n",
       "3  much fun color cookies artist really work well...   \n",
       "4  perfect adding creative touches taste coloring...   \n",
       "\n",
       "                        user_id  category_Grocery   \n",
       "0  AF2BLE54TEMGZ546U763ZHZRXC4A                 1  \\\n",
       "1  AF2BLE54TEMGZ546U763ZHZRXC4A                 1   \n",
       "2  AEUDZQDVSZYCHEXQSXLB6NWQTMHA                 1   \n",
       "3  AGECC4F4CDL2AVODIRNCF3V63BEQ                 1   \n",
       "4  AFF6LERKD46F2RLIKAMQTAQPOIWA                 1   \n",
       "\n",
       "                                   tokenized_reviews  \n",
       "0  [happen, instant, pod, dual, coffee, maker, sp...  \n",
       "1  [tried, leggero, light, roast, lungo, medium, ...  \n",
       "2  [great, roast, ppl, arent, bitter, heavy, tast...  \n",
       "3  [much, fun, color, cookies, artist, really, wo...  \n",
       "4  [perfect, adding, creative, touches, taste, co...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure nltk is downloaded and imported\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Convert any non-string data to string\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenized_data = df['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "\n",
    "df['tokenized_reviews'] = tokenized_data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2492e9fd-e711-46be-972f-c3eae319dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>title_y</th>\n",
       "      <th>user_id</th>\n",
       "      <th>category_Grocery</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>fresh tasting smelling slightly acidic light l...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "      <td>[happen, instant, pod, dual, coffee, maker, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>5</td>\n",
       "      <td>dynamic flavor interesting flavor profile body...</td>\n",
       "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
       "      <td>1</td>\n",
       "      <td>[tried, leggero, light, roast, lungo, medium, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant compostable espresso capsules lungo me...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>85</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B0C2W77WJX</td>\n",
       "      <td>4</td>\n",
       "      <td>pricey much flavor</td>\n",
       "      <td>AEUDZQDVSZYCHEXQSXLB6NWQTMHA</td>\n",
       "      <td>1</td>\n",
       "      <td>[great, roast, ppl, arent, bitter, heavy, tast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>fun</td>\n",
       "      <td>AGECC4F4CDL2AVODIRNCF3V63BEQ</td>\n",
       "      <td>1</td>\n",
       "      <td>[much, fun, color, cookies, artist, really, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edible markersfood coloring markersfood colori...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1193</td>\n",
       "      <td>8.99</td>\n",
       "      <td>B07PK9L29R</td>\n",
       "      <td>5</td>\n",
       "      <td>perfect touch</td>\n",
       "      <td>AFF6LERKD46F2RLIKAMQTAQPOIWA</td>\n",
       "      <td>1</td>\n",
       "      <td>[perfect, adding, creative, touches, taste, co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_x  average_rating   \n",
       "0  instant compostable espresso capsules lungo me...             4.3  \\\n",
       "1  instant compostable espresso capsules lungo me...             4.3   \n",
       "2  instant compostable espresso capsules lungo me...             4.3   \n",
       "3  edible markersfood coloring markersfood colori...             4.3   \n",
       "4  edible markersfood coloring markersfood colori...             4.3   \n",
       "\n",
       "   rating_number  price parent_asin  rating   \n",
       "0             85   8.49  B0C2W77WJX       4  \\\n",
       "1             85   8.49  B0C2W77WJX       5   \n",
       "2             85   8.49  B0C2W77WJX       4   \n",
       "3           1193   8.99  B07PK9L29R       5   \n",
       "4           1193   8.99  B07PK9L29R       5   \n",
       "\n",
       "                                             title_y   \n",
       "0  fresh tasting smelling slightly acidic light l...  \\\n",
       "1  dynamic flavor interesting flavor profile body...   \n",
       "2                                 pricey much flavor   \n",
       "3                                                fun   \n",
       "4                                      perfect touch   \n",
       "\n",
       "                        user_id  category_Grocery   \n",
       "0  AF2BLE54TEMGZ546U763ZHZRXC4A                 1  \\\n",
       "1  AF2BLE54TEMGZ546U763ZHZRXC4A                 1   \n",
       "2  AEUDZQDVSZYCHEXQSXLB6NWQTMHA                 1   \n",
       "3  AGECC4F4CDL2AVODIRNCF3V63BEQ                 1   \n",
       "4  AFF6LERKD46F2RLIKAMQTAQPOIWA                 1   \n",
       "\n",
       "                                   tokenized_reviews  \n",
       "0  [happen, instant, pod, dual, coffee, maker, sp...  \n",
       "1  [tried, leggero, light, roast, lungo, medium, ...  \n",
       "2  [great, roast, ppl, arent, bitter, heavy, tast...  \n",
       "3  [much, fun, color, cookies, artist, really, wo...  \n",
       "4  [perfect, adding, creative, touches, taste, co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now as the data (text - reviews data) is tokenised it's time to drop it the main 'text' column\n",
    "df = df.drop('text', axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a66d1",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "#### To convert the tokenized reviews into a numerical format that can be used for machine learning models, we use the `TfidfVectorizer` from `sklearn.feature_extraction.text`. This process is known as TF-IDF vectorization.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "- **Tokenized Reviews**: We start with the `tokenized_reviews` column which contains the tokenized text data.\n",
    "- **String Conversion**: Each list of tokens is joined into a single string.\n",
    "- **Hyperparameters**: We define hyperparameters such as `ngram_range` to include unigrams and bigrams, and `min_df` to set the minimum document frequency for terms.\n",
    "- **TF-IDF Vectorizer Initialization**: The vectorizer is initialized with the defined hyperparameters.\n",
    "- **Fitting and Transforming**: The vectorizer is then fitted to the tokenized strings and transforms them into a TF-IDF matrix.\n",
    "- **Matrix Shape**: Finally, we print the shape of the TF-IDF matrix to understand the dimensions of our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c554ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (110596, 10000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'tokenized_reviews' column contains the tokenized reviews\n",
    "tokenized_reviews = df['tokenized_reviews']\n",
    "\n",
    "# Convert tokenized reviews into strings\n",
    "tokenized_reviews_str = tokenized_reviews.apply(lambda x: ' '.join(x))\n",
    "\n",
    "# # Define hyperparameters\n",
    "# ngram_range = (1, 2)  # Include unigrams and bigrams\n",
    "# min_df = 2  # Ignore terms that have a document frequency strictly lower than the given threshold\n",
    "\n",
    "# Initialize TF-IDF vectorizer with hyperparameters\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=10000, strip_accents='unicode', \n",
    "                                   analyzer='word', ngram_range=(1, 3), stop_words='english')\n",
    "\n",
    "# Fit and transform the tokenized reviews\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(tokenized_reviews_str)\n",
    "\n",
    "# Print the shape of the TF-IDF matrix\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be5feb",
   "metadata": {},
   "source": [
    "### Here’s a breakdown of what these vectors represent:\n",
    "\n",
    "- TF-IDF: Stands for Term Frequency-Inverse Document Frequency. It’s a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "- Vector Format: Each vector is in the format (document_index, word_id) tf-idf_score.\n",
    "- document_index: The index of the document in the corpus.\n",
    "- word_id: The unique identifier for a word within the corpus.\n",
    "- tf-idf_score: The TF-IDF score for that word in the specified document.\n",
    "- Purpose: These vectors are used to convert text data into a numerical form that can be used for various tasks such as clustering, classification, and information retrieval.\n",
    "\n",
    "#### For example, the vector (0, 8688) 0.13354025856957072 means that in the first document of the corpus (index 0), the word with ID 8688 has a TF-IDF score of approximately 0.134. This score represents the relative importance of this word in that particular document compared to the entire corpus. High scores indicate more importance, and vice versa. The vectors are typically sparse, meaning most of the values are zero, as a word does not appear in most documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324d617e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8688)\t0.13354025856957072\n",
      "  (0, 1766)\t0.1477192016466634\n",
      "  (0, 8231)\t0.14581725775522944\n",
      "  (0, 3729)\t0.1422139670778428\n",
      "  (0, 4907)\t0.12113575777422866\n",
      "  (0, 5586)\t0.11079168371886787\n",
      "  (0, 5033)\t0.14674024378153716\n",
      "  (0, 8940)\t0.13783991642199725\n",
      "  (0, 1007)\t0.1425768555929223\n",
      "  (0, 3198)\t0.09303436837432928\n",
      "  (0, 5851)\t0.14722230523111116\n",
      "  (0, 1751)\t0.11870223660923207\n",
      "  (0, 8108)\t0.15665448279818145\n",
      "  (0, 1166)\t0.1067334936829738\n",
      "  (0, 6713)\t0.1072603212643369\n",
      "  (0, 4073)\t0.09238200984060295\n",
      "  (0, 8675)\t0.06041627082806357\n",
      "  (0, 3439)\t0.129431934122404\n",
      "  (0, 7855)\t0.08894018262606979\n",
      "  (0, 1817)\t0.08011118611107762\n",
      "  (0, 6423)\t0.11498223399854929\n",
      "  (0, 7376)\t0.1185357623581828\n",
      "  (0, 521)\t0.10409122876522635\n",
      "  (0, 5821)\t0.09728635957992757\n",
      "  (0, 899)\t0.10272855302536375\n",
      "  :\t:\n",
      "  (110593, 9382)\t0.1297708145442301\n",
      "  (110593, 6122)\t0.16092951754191354\n",
      "  (110593, 7015)\t0.1272452582061893\n",
      "  (110593, 6636)\t0.13486952244804257\n",
      "  (110593, 8514)\t0.09444501276805845\n",
      "  (110593, 4916)\t0.1790476901031977\n",
      "  (110594, 137)\t0.43795101595331487\n",
      "  (110594, 8278)\t0.3761269026235495\n",
      "  (110594, 947)\t0.3098712029644288\n",
      "  (110594, 3095)\t0.3029031951040808\n",
      "  (110594, 1184)\t0.31087362509014876\n",
      "  (110594, 6433)\t0.25020770015635907\n",
      "  (110594, 5927)\t0.2901551992088973\n",
      "  (110594, 1552)\t0.2621367670227594\n",
      "  (110594, 4793)\t0.25786131261965006\n",
      "  (110594, 9589)\t0.21277276789298477\n",
      "  (110594, 1262)\t0.16828778726723786\n",
      "  (110594, 2535)\t0.16346081433784934\n",
      "  (110595, 5350)\t0.5039372308571523\n",
      "  (110595, 1942)\t0.42251353956191656\n",
      "  (110595, 8738)\t0.43978335825533366\n",
      "  (110595, 608)\t0.3344510346037567\n",
      "  (110595, 8735)\t0.26197808060953626\n",
      "  (110595, 3920)\t0.36857165766577904\n",
      "  (110595, 5307)\t0.24038531141204658\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d311ae1",
   "metadata": {},
   "source": [
    "### Sparse Matrix Conversion\n",
    "The code snippet is converting a dense TF-IDF matrix to a sparse matrix format using the `csr_matrix` class from the `scipy.sparse` module. This is done to optimize memory usage when dealing with large matrices.\n",
    "\n",
    "### Output Explanation\n",
    "- **Type of tfidf_matrix_sparse**: Confirms the matrix is now in CSR format.\n",
    "- **Shape of tfidf_matrix_sparse**: The matrix dimensions reflect the number of documents (rows) and the maximum number of features (columns) considered in the TF-IDF vectorization.\n",
    "- **Number of non-zero entries**: Indicates the total count of non-zero values in the matrix, which represents the actual data points that are stored in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63151f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of tfidf_matrix_sparse: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of tfidf_matrix_sparse: (110596, 10000)\n",
      "Number of non-zero entries: 2118646\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert to a sparse matrix (if not already)\n",
    "tfidf_matrix_sparse = csr_matrix(tfidf_matrix)\n",
    "\n",
    "# Print the type and shape of the sparse TF-IDF matrix\n",
    "print(\"Type of tfidf_matrix_sparse:\", type(tfidf_matrix_sparse))\n",
    "print(\"Shape of tfidf_matrix_sparse:\", tfidf_matrix_sparse.shape)\n",
    "print(\"Number of non-zero entries:\", tfidf_matrix_sparse.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f904240",
   "metadata": {},
   "source": [
    "since i was encountering this error - Unable to allocate 52.8 GiB for an array with shape (110596, 64024) and data type float64\n",
    "i'm using gensim library,  Gensim has an efficient TF-IDF model that doesn’t require loading the entire corpus into memory at once. Instead, it operates on an iterable representation of your data.\n",
    "\n",
    "Here’s how you can use Gensim for TF-IDF representation:\n",
    "\n",
    "Install Gensim (if you haven’t already):\n",
    "pip install gensim\n",
    "\n",
    "Prepare Your Corpus:\n",
    "Ensure your corpus is an iterable (e.g., a list of tokenized reviews).\n",
    "You can use Python generators to achieve this.\n",
    "Create a Gensim Dictionary:\n",
    "Create a dictionary from your tokenized reviews.\n",
    "The dictionary maps words to unique integer IDs.\n",
    "Create a Gensim Corpus:\n",
    "Convert your tokenized reviews into a Gensim corpus using the dictionary.\n",
    "The corpus is a list of bag-of-words representations (sparse vectors) for each document.\n",
    "Compute TF-IDF:\n",
    "Use Gensim’s TfidfModel to compute the TF-IDF scores based on the corpus.\n",
    "Access the TF-IDF Vectors:\n",
    "You can access the TF-IDF vectors for individual documents without loading the entire matrix into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0abfe",
   "metadata": {},
   "source": [
    "### Thoughts behind using gensim and corpora - \n",
    "- Importing Gensim: We start by importing Gensim, a versatile Python library renowned for its capabilities in natural language processing tasks such as topic modeling, document similarity analysis, and text summarization. This step ensures we have access to the tools necessary for our task ahead.\n",
    "- Creating a Dictionary: In this step, we construct a dictionary that serves as a fundamental component in the subsequent processes. This dictionary acts as a mapping between words and their unique integer IDs within our corpus of product reviews. By establishing this mapping, we lay the groundwork for efficient representation and analysis of textual data.\n",
    "- Creating a Corpus: With our dictionary in place, we proceed to create a corpus, essentially a collection of documents represented in a format suitable for computational analysis. Each document is transformed into a bag-of-words vector, where each word's frequency within the document is recorded. This step transforms our raw textual data into a structured format amenable to further processing.\n",
    "- TF-IDF Model: Building upon the bag-of-words representation, we leverage Gensim's capabilities to construct a TF-IDF model. TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document relative to a corpus. By applying this model to our corpus, we compute TF-IDF scores for each word, capturing their significance within individual documents and across the entire corpus.\n",
    "- Accessing TF-IDF Vectors: Here, we access the TF-IDF vectors generated by our model, enabling us to explore and utilize the transformed textual data. These vectors encapsulate the essence of each document's content, with each dimension representing a unique word and its corresponding TF-IDF score. By retrieving these vectors, we gain valuable insights into the semantic composition of our product reviews, paving the way for various downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335b1dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0.15822019336594337), (1, 0.07911009668297168), (2, 0.12170821532633551), (3, 0.07493418887314095), (4, 0.11030375926386878), (5, 0.10859182482154411), (6, 0.04947903549083479), (7, 0.10374842137816317), (8, 0.1136241355227434), (9, 0.13596692814909372), (10, 0.13138885661596642), (11, 0.09599582425095556), (12, 0.1565601201334325), (13, 0.08020523861709881), (14, 0.08266694420118104), (15, 0.11723536349072858), (16, 0.18658037825369134), (17, 0.0888713835981412), (18, 0.07936684071231864), (19, 0.07183341245268707), (20, 0.12707538562583412), (21, 0.07401393015048931), (22, 0.032219935791116754), (23, 0.12179428611948441), (24, 0.05987914001758319), (25, 0.120831002481178), (26, 0.09560107520762093), (27, 0.06796589385054766), (28, 0.10209478190637414), (29, 0.11026127062439335), (30, 0.2560739659343325), (31, 0.028176078444046855), (32, 0.11693806256431222), (33, 0.1019816764207001), (34, 0.11392707128848491), (35, 0.1524549702782134), (36, 0.3968735655113111), (37, 0.10175734360716843), (38, 0.1205468458267122), (39, 0.14494580166562673), (40, 0.17899439864420652), (41, 0.11034633725911869), (42, 0.12399966044774859), (43, 0.11944849764833426), (44, 0.15867835234489372), (45, 0.11428632229866684), (46, 0.1485431044461317), (47, 0.2659537149160561), (48, 0.12847559962027527), (49, 0.09128183907513461), (50, 0.14230128775197218), (51, 0.1559351244263627), (52, 0.07034985227279414), (53, 0.12529514467356573), (54, 0.055505412590967515), (55, 0.07660234476498358), (56, 0.10170164665517933), (57, 0.058133556316320174), (58, 0.08849130632677189)], [(0, 0.11416457669124039), (1, 0.057082288345620194), (2, 0.1756383504151153), (4, 0.07959023254817132), (5, 0.07835497763681423), (6, 0.07140369407635799), (8, 0.08198606674598023), (9, 0.09810762119502503), (10, 0.18960858128664884), (11, 0.06926627004171028), (14, 0.059648749570531484), (20, 0.045845941972449275), (22, 0.04649691360323611), (24, 0.021603047396522624), (25, 0.08718621786497685), (28, 0.07366700362808785), (29, 0.07955957465655392), (30, 0.43113340361148905), (31, 0.04066118236809315), (36, 0.14318305913628962), (38, 0.08698118320106354), (43, 0.08618866454603892), (44, 0.11449516360796967), (46, 0.1071820244857923), (47, 0.4477672296616153), (48, 0.09270221539850006), (51, 0.11251577369936086), (52, 0.05076128990968353), (53, 0.09040734212757148), (57, 0.04194656008957726), (59, 0.048030471594611615), (60, 0.04125404222963803), (61, 0.055342676638254575), (62, 0.05870789929889441), (63, 0.10425053064574136), (64, 0.08765834628045986), (65, 0.06361296319487746), (66, 0.09120075773748264), (67, 0.08888106172324096), (68, 0.08087250080371218), (69, 0.09379640966047523), (70, 0.03405476603602033), (71, 0.04996449255495275), (72, 0.06409368616979012), (73, 0.0955170407805), (74, 0.1461461743812108), (75, 0.054149599195664394), (76, 0.10738634222187224), (77, 0.1536085602864444), (78, 0.04682556039124491), (79, 0.2601942374819704), (80, 0.20941787593289363), (81, 0.15113035449017623), (82, 0.03143056760768222), (83, 0.07228210868878054), (84, 0.07734709665396505), (85, 0.06703817110006498), (86, 0.06425392704512127), (87, 0.08367058294033307), (88, 0.12698023221598426), (89, 0.12323108012601793), (90, 0.047019053021239245), (91, 0.08899746457015016), (92, 0.10139468938281304), (93, 0.09347533124138291), (94, 0.04212494348851259), (95, 0.03228047043631043)], [(22, 0.059435528639504104), (31, 0.05197589865377), (47, 0.16353332444188057), (53, 0.23112967101845402), (61, 0.14148557344635723), (66, 0.23315806699364935), (71, 0.1277360494741096), (96, 0.16753711121382117), (97, 0.19727257776792978), (98, 0.13869761031581512), (99, 0.26028130020535134), (100, 0.33794243734996116), (101, 0.17620205218625346), (102, 0.1581279374627826), (103, 0.14563163126522014), (104, 0.26652028789486004), (105, 0.07933663480085813), (106, 0.1962888392659639), (107, 0.19890252861837474), (108, 0.15938361993832514), (109, 0.18280014949331955), (110, 0.33259803404708693), (111, 0.09722253555362718), (112, 0.3257888503586839), (113, 0.056886161162777525), (114, 0.11680398930026273), (115, 0.14192080692811235)], [(57, 0.14714870634845528), (105, 0.10886339464803592), (115, 0.19473955319838818), (116, 0.5241167345705715), (117, 0.46312326779036983), (118, 0.2147881412031032), (119, 0.26934176660823517), (120, 0.12337660264907935), (121, 0.12296654558415389), (122, 0.5388594650414585)], [(3, 0.232654913903139), (113, 0.09574528300880353), (123, 0.28223500802093854), (124, 0.4060912910436275), (125, 0.4769925179797686), (126, 0.29322123326761207), (127, 0.23476133370226132), (128, 0.5687920162545391)], [(70, 0.10139706025857939), (129, 0.18392019026419607), (130, 0.16359835555657576), (131, 0.1951919848113645), (132, 0.13788735301426827), (133, 0.11962204628105651), (134, 0.10473082480338733), (135, 0.15795967604798405), (136, 0.27277867311113235), (137, 0.1645904498555037), (138, 0.1631441257157089), (139, 0.19964288987582682), (140, 0.13047513642393369), (141, 0.21940228987999869), (142, 0.14351792159564555), (143, 0.3791180752579176), (144, 0.22838224896242873), (145, 0.5051505415496846), (146, 0.29051909515877405), (147, 0.18052173063526142)], [(6, 0.043166148684837584), (12, 0.13658506793342023), (19, 0.06266839544692261), (28, 0.17813760886802033), (78, 0.05661553308258239), (148, 0.13500232264754844), (149, 0.09899648696849205), (150, 0.14391415548664527), (151, 0.1707584161302298), (152, 0.0671406183730905), (153, 0.18064275453849296), (154, 0.15615702183726118), (155, 0.09645447660395232), (156, 0.10486155973036489), (157, 0.12645258671423348), (158, 0.16839988818787707), (159, 0.1857240031726577), (160, 0.15221569919704678), (161, 0.16277512828365348), (162, 0.07713789819859809), (163, 0.19288562088910888), (164, 0.18064275453849296), (165, 0.20512848723972477), (166, 0.09456723643375421), (167, 0.08801256614762654), (168, 0.2533183412394839), (169, 0.17348113682204178), (170, 0.14758163198139668), (171, 0.12545442722251762), (172, 0.18064275453849296), (173, 0.17348113682204178), (174, 0.12751055097145647), (175, 0.0646636528142584), (176, 0.09147687721269282), (177, 0.13112777786597052), (178, 0.20512848723972477), (179, 0.041795160943454514), (180, 0.06867812601598983), (181, 0.15407665275497473), (182, 0.09568241368812605), (183, 0.09320289237414721), (184, 0.1428433596105722), (185, 0.21163023716845428), (186, 0.040176367004863774), (187, 0.06190280952912888), (188, 0.16895330144111895), (189, 0.1343480729422073), (190, 0.08810601992421778), (191, 0.05411136978470962), (192, 0.07718832713384043), (193, 0.10217343791851013), (194, 0.17348113682204178), (195, 0.05055641624800683), (196, 0.10111486961133685)], [(70, 0.1509496322911158), (105, 0.13755485842037654), (197, 0.2875815034401167), (198, 0.17822786624059955), (199, 0.3793157875272854), (200, 0.5276003253191869), (201, 0.6029177073726111), (202, 0.24098183376090862)], [(203, 0.5490947594964163), (204, 0.3018565936175597), (205, 0.350260591151986), (206, 0.3249014435357001), (207, 0.4794010402625605), (208, 0.24893736516291362), (209, 0.2955316278816479)], [(23, 0.10959111430586523), (113, 0.11099248836856532), (127, 0.13607325489831845), (140, 0.10929222338395803), (143, 0.15878372886063516), (147, 0.15121364768029927), (202, 0.13559357485837867), (210, 0.1611763563170237), (211, 0.2836432736270073), (212, 0.18487109556396963), (213, 0.21354561020957816), (214, 0.15437817183678681), (215, 0.22110197096081133), (216, 0.11501021075291555), (217, 0.3650524848235283), (218, 0.1223310269301099), (219, 0.09544826782747899), (220, 0.17275505581684597), (221, 0.14377140549585818), (222, 0.1804162814086015), (223, 0.24994313515184197), (224, 0.1628922353642523), (225, 0.2739624853167774), (226, 0.23274030301843568), (227, 0.2612720705641176), (228, 0.19472627830766778), (229, 0.14662388003518012), (230, 0.14240013896124945)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Assuming 'tokenized_reviews' is an iterable (e.g., list of lists)\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "corpus = [dictionary.doc2bow(review) for review in tokenized_reviews]\n",
    "\n",
    "# Create the TF-IDF model\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "\n",
    "# # Get the TF-IDF vectors for a specific document (e.g., first document)\n",
    "# doc_index = 0\n",
    "# tfidf_vector = tfidf_model[corpus[doc_index]]\n",
    "\n",
    "# # Print the TF-IDF vector for the first document\n",
    "# print(tfidf_vector)\n",
    "\n",
    "\n",
    "# Create a list to hold all TF-IDF vectors\n",
    "all_tfidf_vectors = []\n",
    "\n",
    "# Iterate over all documents in the corpus\n",
    "for doc in corpus:\n",
    "    # Apply the TF-IDF model to get the vector for the current document\n",
    "    doc_tfidf_vector = tfidf_model[doc]\n",
    "    # Append the vector to the list\n",
    "    all_tfidf_vectors.append(doc_tfidf_vector)\n",
    "\n",
    "# Now 'all_tfidf_vectors' contains the TF-IDF vectors for all documents\n",
    "# Limit the output to the first 10 TF-IDF vectors\n",
    "limited_tfidf_vectors = all_tfidf_vectors[:10]\n",
    "\n",
    "# Now 'limited_tfidf_vectors' contains the TF-IDF vectors for the first 10 documents\n",
    "print(limited_tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1249bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110596\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tfidf_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594816af",
   "metadata": {},
   "source": [
    "#### Applying padding on the vectors to obtain it in equal lengths \n",
    "- Importing NumPy: The code begins by importing the NumPy library, which is a fundamental package for scientific computing in Python.\n",
    "- Max Length Calculation: max_length is determined by finding the longest vector in all_tfidf_vectors, which is a list of TF-IDF vectors. This ensures that all vectors will be padded to the same length.\n",
    "- Padding Function: pad_vector is a function that takes a vector and the max_length as arguments. It calculates the necessary padding (a list of zeros) to make the vector’s length equal to max_length. The padding is then appended to the original vector, and the padded vector is returned.\n",
    "- Applying Padding: The list comprehension applies the pad_vector function to each vector in all_tfidf_vectors. The result is padded_vectors, a new list where each TF-IDF vector has been padded with zeros to have the same length, ensuring uniformity for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a50b118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'all_tfidf_vectors' is a list of TF-IDF vectors\n",
    "max_length = max(len(vector) for vector in all_tfidf_vectors)\n",
    "\n",
    "# Function to pad the vectors\n",
    "def pad_vector(vector, max_length):\n",
    "    padding = [0] * (max_length - len(vector))\n",
    "    return vector + padding\n",
    "\n",
    "# Apply padding to each vector\n",
    "padded_vectors = [pad_vector(vector, max_length) for vector in all_tfidf_vectors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1205dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All vectors are of the same length: 576\n",
      "[[(0, 0.15822019336594337), (1, 0.07911009668297168), (2, 0.12170821532633551), (3, 0.07493418887314095), (4, 0.11030375926386878), (5, 0.10859182482154411), (6, 0.04947903549083479), (7, 0.10374842137816317), (8, 0.1136241355227434), (9, 0.13596692814909372), (10, 0.13138885661596642), (11, 0.09599582425095556), (12, 0.1565601201334325), (13, 0.08020523861709881), (14, 0.08266694420118104), (15, 0.11723536349072858), (16, 0.18658037825369134), (17, 0.0888713835981412), (18, 0.07936684071231864), (19, 0.07183341245268707), (20, 0.12707538562583412), (21, 0.07401393015048931), (22, 0.032219935791116754), (23, 0.12179428611948441), (24, 0.05987914001758319), (25, 0.120831002481178), (26, 0.09560107520762093), (27, 0.06796589385054766), (28, 0.10209478190637414), (29, 0.11026127062439335), (30, 0.2560739659343325), (31, 0.028176078444046855), (32, 0.11693806256431222), (33, 0.1019816764207001), (34, 0.11392707128848491), (35, 0.1524549702782134), (36, 0.3968735655113111), (37, 0.10175734360716843), (38, 0.1205468458267122), (39, 0.14494580166562673), (40, 0.17899439864420652), (41, 0.11034633725911869), (42, 0.12399966044774859), (43, 0.11944849764833426), (44, 0.15867835234489372), (45, 0.11428632229866684), (46, 0.1485431044461317), (47, 0.2659537149160561), (48, 0.12847559962027527), (49, 0.09128183907513461), (50, 0.14230128775197218), (51, 0.1559351244263627), (52, 0.07034985227279414), (53, 0.12529514467356573), (54, 0.055505412590967515), (55, 0.07660234476498358), (56, 0.10170164665517933), (57, 0.058133556316320174), (58, 0.08849130632677189), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(0, 0.11416457669124039), (1, 0.057082288345620194), (2, 0.1756383504151153), (4, 0.07959023254817132), (5, 0.07835497763681423), (6, 0.07140369407635799), (8, 0.08198606674598023), (9, 0.09810762119502503), (10, 0.18960858128664884), (11, 0.06926627004171028), (14, 0.059648749570531484), (20, 0.045845941972449275), (22, 0.04649691360323611), (24, 0.021603047396522624), (25, 0.08718621786497685), (28, 0.07366700362808785), (29, 0.07955957465655392), (30, 0.43113340361148905), (31, 0.04066118236809315), (36, 0.14318305913628962), (38, 0.08698118320106354), (43, 0.08618866454603892), (44, 0.11449516360796967), (46, 0.1071820244857923), (47, 0.4477672296616153), (48, 0.09270221539850006), (51, 0.11251577369936086), (52, 0.05076128990968353), (53, 0.09040734212757148), (57, 0.04194656008957726), (59, 0.048030471594611615), (60, 0.04125404222963803), (61, 0.055342676638254575), (62, 0.05870789929889441), (63, 0.10425053064574136), (64, 0.08765834628045986), (65, 0.06361296319487746), (66, 0.09120075773748264), (67, 0.08888106172324096), (68, 0.08087250080371218), (69, 0.09379640966047523), (70, 0.03405476603602033), (71, 0.04996449255495275), (72, 0.06409368616979012), (73, 0.0955170407805), (74, 0.1461461743812108), (75, 0.054149599195664394), (76, 0.10738634222187224), (77, 0.1536085602864444), (78, 0.04682556039124491), (79, 0.2601942374819704), (80, 0.20941787593289363), (81, 0.15113035449017623), (82, 0.03143056760768222), (83, 0.07228210868878054), (84, 0.07734709665396505), (85, 0.06703817110006498), (86, 0.06425392704512127), (87, 0.08367058294033307), (88, 0.12698023221598426), (89, 0.12323108012601793), (90, 0.047019053021239245), (91, 0.08899746457015016), (92, 0.10139468938281304), (93, 0.09347533124138291), (94, 0.04212494348851259), (95, 0.03228047043631043), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(22, 0.059435528639504104), (31, 0.05197589865377), (47, 0.16353332444188057), (53, 0.23112967101845402), (61, 0.14148557344635723), (66, 0.23315806699364935), (71, 0.1277360494741096), (96, 0.16753711121382117), (97, 0.19727257776792978), (98, 0.13869761031581512), (99, 0.26028130020535134), (100, 0.33794243734996116), (101, 0.17620205218625346), (102, 0.1581279374627826), (103, 0.14563163126522014), (104, 0.26652028789486004), (105, 0.07933663480085813), (106, 0.1962888392659639), (107, 0.19890252861837474), (108, 0.15938361993832514), (109, 0.18280014949331955), (110, 0.33259803404708693), (111, 0.09722253555362718), (112, 0.3257888503586839), (113, 0.056886161162777525), (114, 0.11680398930026273), (115, 0.14192080692811235), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(57, 0.14714870634845528), (105, 0.10886339464803592), (115, 0.19473955319838818), (116, 0.5241167345705715), (117, 0.46312326779036983), (118, 0.2147881412031032), (119, 0.26934176660823517), (120, 0.12337660264907935), (121, 0.12296654558415389), (122, 0.5388594650414585), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(3, 0.232654913903139), (113, 0.09574528300880353), (123, 0.28223500802093854), (124, 0.4060912910436275), (125, 0.4769925179797686), (126, 0.29322123326761207), (127, 0.23476133370226132), (128, 0.5687920162545391), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(70, 0.10139706025857939), (129, 0.18392019026419607), (130, 0.16359835555657576), (131, 0.1951919848113645), (132, 0.13788735301426827), (133, 0.11962204628105651), (134, 0.10473082480338733), (135, 0.15795967604798405), (136, 0.27277867311113235), (137, 0.1645904498555037), (138, 0.1631441257157089), (139, 0.19964288987582682), (140, 0.13047513642393369), (141, 0.21940228987999869), (142, 0.14351792159564555), (143, 0.3791180752579176), (144, 0.22838224896242873), (145, 0.5051505415496846), (146, 0.29051909515877405), (147, 0.18052173063526142), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(6, 0.043166148684837584), (12, 0.13658506793342023), (19, 0.06266839544692261), (28, 0.17813760886802033), (78, 0.05661553308258239), (148, 0.13500232264754844), (149, 0.09899648696849205), (150, 0.14391415548664527), (151, 0.1707584161302298), (152, 0.0671406183730905), (153, 0.18064275453849296), (154, 0.15615702183726118), (155, 0.09645447660395232), (156, 0.10486155973036489), (157, 0.12645258671423348), (158, 0.16839988818787707), (159, 0.1857240031726577), (160, 0.15221569919704678), (161, 0.16277512828365348), (162, 0.07713789819859809), (163, 0.19288562088910888), (164, 0.18064275453849296), (165, 0.20512848723972477), (166, 0.09456723643375421), (167, 0.08801256614762654), (168, 0.2533183412394839), (169, 0.17348113682204178), (170, 0.14758163198139668), (171, 0.12545442722251762), (172, 0.18064275453849296), (173, 0.17348113682204178), (174, 0.12751055097145647), (175, 0.0646636528142584), (176, 0.09147687721269282), (177, 0.13112777786597052), (178, 0.20512848723972477), (179, 0.041795160943454514), (180, 0.06867812601598983), (181, 0.15407665275497473), (182, 0.09568241368812605), (183, 0.09320289237414721), (184, 0.1428433596105722), (185, 0.21163023716845428), (186, 0.040176367004863774), (187, 0.06190280952912888), (188, 0.16895330144111895), (189, 0.1343480729422073), (190, 0.08810601992421778), (191, 0.05411136978470962), (192, 0.07718832713384043), (193, 0.10217343791851013), (194, 0.17348113682204178), (195, 0.05055641624800683), (196, 0.10111486961133685), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(70, 0.1509496322911158), (105, 0.13755485842037654), (197, 0.2875815034401167), (198, 0.17822786624059955), (199, 0.3793157875272854), (200, 0.5276003253191869), (201, 0.6029177073726111), (202, 0.24098183376090862), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(203, 0.5490947594964163), (204, 0.3018565936175597), (205, 0.350260591151986), (206, 0.3249014435357001), (207, 0.4794010402625605), (208, 0.24893736516291362), (209, 0.2955316278816479), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(23, 0.10959111430586523), (113, 0.11099248836856532), (127, 0.13607325489831845), (140, 0.10929222338395803), (143, 0.15878372886063516), (147, 0.15121364768029927), (202, 0.13559357485837867), (210, 0.1611763563170237), (211, 0.2836432736270073), (212, 0.18487109556396963), (213, 0.21354561020957816), (214, 0.15437817183678681), (215, 0.22110197096081133), (216, 0.11501021075291555), (217, 0.3650524848235283), (218, 0.1223310269301099), (219, 0.09544826782747899), (220, 0.17275505581684597), (221, 0.14377140549585818), (222, 0.1804162814086015), (223, 0.24994313515184197), (224, 0.1628922353642523), (225, 0.2739624853167774), (226, 0.23274030301843568), (227, 0.2612720705641176), (228, 0.19472627830766778), (229, 0.14662388003518012), (230, 0.14240013896124945), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'padded_vectors' is a list of lists (vectors)\n",
    "vector_lengths = [len(vector) for vector in padded_vectors]\n",
    "\n",
    "# Check if all vectors are of the same length\n",
    "if len(set(vector_lengths)) == 1:\n",
    "    print(\"All vectors are of the same length:\", vector_lengths[0])\n",
    "else:\n",
    "    print(\"Vectors are of varying lengths\")\n",
    "limited_padded_vectors = padded_vectors[:10]\n",
    "\n",
    "# Now 'limited_tfidf_vectors' contains the TF-IDF vectors for the first 10 documents\n",
    "print(limited_padded_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f45cf",
   "metadata": {},
   "source": [
    "### Model Building and its steps\n",
    "- Normalization: The TF-IDF matrix, stored in tfidf_matrix_sparse, is normalized using sklearn's normalize function. Normalization ensures that each TF-IDF vector has a unit norm, which can improve the performance of subsequent operations.\n",
    "- Dimensionality Reduction: Truncated Singular Value Decomposition (SVD) is applied to the normalized TF-IDF matrix to reduce its dimensionality while preserving important information. This step is crucial for managing computational complexity and capturing the most relevant features.\n",
    "- Chunk-based Similarity Calculation: To handle large datasets efficiently, the code defines a function chunk_similarity that calculates cosine similarity scores between a reference document and chunks of the TF-IDF matrix. This approach enables memory-efficient computation by processing the data in manageable chunks.\n",
    "- Recommendation Generation: Another function, get_recommendations_in_chunks, utilizes the chunk-based similarity calculation to generate recommendations for a given product index. It calculates cosine similarity scores between the reference product and all other products in the dataset, filtering out low similarity scores based on a threshold. Finally, it returns the top N products with the highest similarity scores as recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbfb5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the TF-IDF matrix\n",
    "normalized_tfidf_matrix_sparse = normalize(tfidf_matrix_sparse)\n",
    "\n",
    "# Initialize Truncated SVD with desired number of components\n",
    "n_components = 100  # Adjust the number of components as needed\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Apply Truncated SVD to the normalized TF-IDF matrix\n",
    "tfidf_matrix_reduced = svd.fit_transform(normalized_tfidf_matrix_sparse)\n",
    "\n",
    "# Define a function to calculate cosine similarity in chunks\n",
    "def chunk_similarity(matrix, ref_idx, chunk_size=1000):\n",
    "    num_chunks = matrix.shape[0] // chunk_size + (1 if matrix.shape[0] % chunk_size != 0 else 0)\n",
    "    sim_scores = []\n",
    "\n",
    "    for chunk_start in range(0, matrix.shape[0], chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, matrix.shape[0])\n",
    "        sim_chunk = cosine_similarity(matrix[ref_idx:ref_idx+1], matrix[chunk_start:chunk_end])\n",
    "        sim_scores.extend(sim_chunk.flatten())\n",
    "\n",
    "    return sim_scores\n",
    "\n",
    "# Get recommendations based on cosine similarity matrix in chunks\n",
    "def get_recommendations_in_chunks(product_index, matrix, n=5, threshold=0.2, chunk_size=1000):\n",
    "    num_docs = matrix.shape[0]\n",
    "    sim_scores = np.zeros(num_docs)\n",
    "\n",
    "    for chunk_start in range(0, num_docs, chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, num_docs)\n",
    "        sim_chunk = cosine_similarity(matrix[product_index:product_index+1], matrix[chunk_start:chunk_end])\n",
    "        sim_scores[chunk_start:chunk_end] = sim_chunk.flatten()\n",
    "\n",
    "    # Filter out low similarity scores based on threshold\n",
    "    sim_indices = [(idx, score) for idx, score in enumerate(sim_scores) if score > threshold]\n",
    "    # Sort the products based on similarity scores\n",
    "    sim_indices = sorted(sim_indices, key=lambda x: x[1], reverse=True)\n",
    "    # Get the top similar products\n",
    "    top_similar_products = sim_indices[:n]  # Limit to top N\n",
    "    return top_similar_products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b67e91",
   "metadata": {},
   "source": [
    "### Getting Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3fd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended products:\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n",
      "|                                                                                 Title                                                                                 | Price | Avg Rating | Cosine Similarity Score |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n",
      "| instant compostable espresso capsules lungo medium roast 10 plantbased capsules makers instant pot ecofriendly 100 organic arabica capsules compostable freshness bag | 8.49  |    4.3     |   1.0000000000000004    |\n",
      "|                   holland valley coffee keurig kcup coffee maker compatible high caffeine roast 100 organic coffee single serve pods usda approved                    | 15.0  |    4.1     |   0.8797973038330694    |\n",
      "|                                     bean coffee company organic il chicco traditional italian roast dark roast ground 16ounce bag                                     | 14.99 |    4.2     |   0.8567460489902224    |\n",
      "|                                        brooklyn beans expresso gourmet coffee pods compatible 20 keurig k cup brewers 40 count                                        | 23.98 |    4.3     |   0.8516359381925976    |\n",
      "|        dr mercola solspring biodynamic organic brazilian medium roast coffee 1lb 16 oz whole bean coffee pack two 2 non gmo soy free gluten free usda organic         | 44.97 |    3.6     |   0.8458524269529825    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Example usage\n",
    "product_index = 0\n",
    "top_similar_products = get_recommendations_in_chunks(product_index, tfidf_matrix_reduced)\n",
    "\n",
    "# Prepare the data for tabular display\n",
    "table_data = []\n",
    "for index, score in top_similar_products:\n",
    "    title = df.iloc[index]['title_x']\n",
    "    price = df.iloc[index]['price']\n",
    "    avg_rating = df.iloc[index]['average_rating']\n",
    "    table_data.append([title, price, avg_rating, score])\n",
    "\n",
    "# Display the recommendations in a tabular format\n",
    "print(\"Top 5 recommended products:\")\n",
    "print(tabulate(table_data, headers=['Title', 'Price', 'Avg Rating', 'Cosine Similarity Score'], tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f909b",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9627cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.9967362727776101\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming get_recommendations_in_chunks is defined and returns a list of tuples (index, score)\n",
    "product_index = 0\n",
    "top_similar_products = get_recommendations_in_chunks(product_index, tfidf_matrix_reduced)\n",
    "\n",
    "# Extract the indices and scores from the recommendations\n",
    "top_indices = [index for index, score in top_similar_products]\n",
    "top_scores = [score for index, score in top_similar_products]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'average_rating' is a column in your dataset\n",
    "# Prepare relevance scores based on the average_rating of the recommended products\n",
    "relevance_scores = df.loc[top_indices, 'average_rating'].tolist()\n",
    "\n",
    "# Normalize relevance scores since NDCG in sklearn assumes relevance scores, not ratings directly\n",
    "max_rating = max(relevance_scores)\n",
    "normalized_relevance_scores = [score / max_rating for score in relevance_scores]\n",
    "\n",
    "# Reshape for ndcg_score function\n",
    "true_relevance = np.asarray([normalized_relevance_scores])\n",
    "predicted_relevance = np.asarray([top_scores])\n",
    "\n",
    "# Calculate NDCG score\n",
    "ndcg = ndcg_score(true_relevance, predicted_relevance)\n",
    "print(\"NDCG Score:\", ndcg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb559c",
   "metadata": {},
   "source": [
    "### Using bi gram\n",
    "#### For this model, all the above pre-processing and feature engineering were performed similarly below for bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a52ae29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (110596, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer to use only bigrams\n",
    "tfidf_vectorizer_bigram = TfidfVectorizer(min_df=5, max_features=10000, strip_accents='unicode', \n",
    "                                   analyzer='word', ngram_range=(2, 2), stop_words='english')\n",
    "\n",
    "# Fit and transform the tokenized reviews\n",
    "tfidf_matrix_bigram = tfidf_vectorizer_bigram.fit_transform(tokenized_reviews_str)\n",
    "\n",
    "# Print the shape of the TF-IDF matrix\n",
    "print(\"Shape of TF-IDF matrix:\", tfidf_matrix_bigram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3030b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of tfidf_matrix_sparse_bigram: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of tfidf_matrix_sparse_bigram: (110596, 10000)\n",
      "Number of non-zero entries: 490379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert to a sparse matrix (if not already)\n",
    "tfidf_matrix_sparse_bigram = csr_matrix(tfidf_matrix_bigram)\n",
    "\n",
    "# Print the type and shape of the sparse TF-IDF matrix\n",
    "print(\"Type of tfidf_matrix_sparse_bigram:\", type(tfidf_matrix_sparse_bigram))\n",
    "print(\"Shape of tfidf_matrix_sparse_bigram:\", tfidf_matrix_sparse_bigram.shape)\n",
    "print(\"Number of non-zero entries:\", tfidf_matrix_sparse_bigram.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f75aa3a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0.15822019336594337), (1, 0.07911009668297168), (2, 0.12170821532633551), (3, 0.07493418887314095), (4, 0.11030375926386878), (5, 0.10859182482154411), (6, 0.04947903549083479), (7, 0.10374842137816317), (8, 0.1136241355227434), (9, 0.13596692814909372), (10, 0.13138885661596642), (11, 0.09599582425095556), (12, 0.1565601201334325), (13, 0.08020523861709881), (14, 0.08266694420118104), (15, 0.11723536349072858), (16, 0.18658037825369134), (17, 0.0888713835981412), (18, 0.07936684071231864), (19, 0.07183341245268707), (20, 0.12707538562583412), (21, 0.07401393015048931), (22, 0.032219935791116754), (23, 0.12179428611948441), (24, 0.05987914001758319), (25, 0.120831002481178), (26, 0.09560107520762093), (27, 0.06796589385054766), (28, 0.10209478190637414), (29, 0.11026127062439335), (30, 0.2560739659343325), (31, 0.028176078444046855), (32, 0.11693806256431222), (33, 0.1019816764207001), (34, 0.11392707128848491), (35, 0.1524549702782134), (36, 0.3968735655113111), (37, 0.10175734360716843), (38, 0.1205468458267122), (39, 0.14494580166562673), (40, 0.17899439864420652), (41, 0.11034633725911869), (42, 0.12399966044774859), (43, 0.11944849764833426), (44, 0.15867835234489372), (45, 0.11428632229866684), (46, 0.1485431044461317), (47, 0.2659537149160561), (48, 0.12847559962027527), (49, 0.09128183907513461), (50, 0.14230128775197218), (51, 0.1559351244263627), (52, 0.07034985227279414), (53, 0.12529514467356573), (54, 0.055505412590967515), (55, 0.07660234476498358), (56, 0.10170164665517933), (57, 0.058133556316320174), (58, 0.08849130632677189)], [(0, 0.11416457669124039), (1, 0.057082288345620194), (2, 0.1756383504151153), (4, 0.07959023254817132), (5, 0.07835497763681423), (6, 0.07140369407635799), (8, 0.08198606674598023), (9, 0.09810762119502503), (10, 0.18960858128664884), (11, 0.06926627004171028), (14, 0.059648749570531484), (20, 0.045845941972449275), (22, 0.04649691360323611), (24, 0.021603047396522624), (25, 0.08718621786497685), (28, 0.07366700362808785), (29, 0.07955957465655392), (30, 0.43113340361148905), (31, 0.04066118236809315), (36, 0.14318305913628962), (38, 0.08698118320106354), (43, 0.08618866454603892), (44, 0.11449516360796967), (46, 0.1071820244857923), (47, 0.4477672296616153), (48, 0.09270221539850006), (51, 0.11251577369936086), (52, 0.05076128990968353), (53, 0.09040734212757148), (57, 0.04194656008957726), (59, 0.048030471594611615), (60, 0.04125404222963803), (61, 0.055342676638254575), (62, 0.05870789929889441), (63, 0.10425053064574136), (64, 0.08765834628045986), (65, 0.06361296319487746), (66, 0.09120075773748264), (67, 0.08888106172324096), (68, 0.08087250080371218), (69, 0.09379640966047523), (70, 0.03405476603602033), (71, 0.04996449255495275), (72, 0.06409368616979012), (73, 0.0955170407805), (74, 0.1461461743812108), (75, 0.054149599195664394), (76, 0.10738634222187224), (77, 0.1536085602864444), (78, 0.04682556039124491), (79, 0.2601942374819704), (80, 0.20941787593289363), (81, 0.15113035449017623), (82, 0.03143056760768222), (83, 0.07228210868878054), (84, 0.07734709665396505), (85, 0.06703817110006498), (86, 0.06425392704512127), (87, 0.08367058294033307), (88, 0.12698023221598426), (89, 0.12323108012601793), (90, 0.047019053021239245), (91, 0.08899746457015016), (92, 0.10139468938281304), (93, 0.09347533124138291), (94, 0.04212494348851259), (95, 0.03228047043631043)], [(22, 0.059435528639504104), (31, 0.05197589865377), (47, 0.16353332444188057), (53, 0.23112967101845402), (61, 0.14148557344635723), (66, 0.23315806699364935), (71, 0.1277360494741096), (96, 0.16753711121382117), (97, 0.19727257776792978), (98, 0.13869761031581512), (99, 0.26028130020535134), (100, 0.33794243734996116), (101, 0.17620205218625346), (102, 0.1581279374627826), (103, 0.14563163126522014), (104, 0.26652028789486004), (105, 0.07933663480085813), (106, 0.1962888392659639), (107, 0.19890252861837474), (108, 0.15938361993832514), (109, 0.18280014949331955), (110, 0.33259803404708693), (111, 0.09722253555362718), (112, 0.3257888503586839), (113, 0.056886161162777525), (114, 0.11680398930026273), (115, 0.14192080692811235)], [(57, 0.14714870634845528), (105, 0.10886339464803592), (115, 0.19473955319838818), (116, 0.5241167345705715), (117, 0.46312326779036983), (118, 0.2147881412031032), (119, 0.26934176660823517), (120, 0.12337660264907935), (121, 0.12296654558415389), (122, 0.5388594650414585)], [(3, 0.232654913903139), (113, 0.09574528300880353), (123, 0.28223500802093854), (124, 0.4060912910436275), (125, 0.4769925179797686), (126, 0.29322123326761207), (127, 0.23476133370226132), (128, 0.5687920162545391)], [(70, 0.10139706025857939), (129, 0.18392019026419607), (130, 0.16359835555657576), (131, 0.1951919848113645), (132, 0.13788735301426827), (133, 0.11962204628105651), (134, 0.10473082480338733), (135, 0.15795967604798405), (136, 0.27277867311113235), (137, 0.1645904498555037), (138, 0.1631441257157089), (139, 0.19964288987582682), (140, 0.13047513642393369), (141, 0.21940228987999869), (142, 0.14351792159564555), (143, 0.3791180752579176), (144, 0.22838224896242873), (145, 0.5051505415496846), (146, 0.29051909515877405), (147, 0.18052173063526142)], [(6, 0.043166148684837584), (12, 0.13658506793342023), (19, 0.06266839544692261), (28, 0.17813760886802033), (78, 0.05661553308258239), (148, 0.13500232264754844), (149, 0.09899648696849205), (150, 0.14391415548664527), (151, 0.1707584161302298), (152, 0.0671406183730905), (153, 0.18064275453849296), (154, 0.15615702183726118), (155, 0.09645447660395232), (156, 0.10486155973036489), (157, 0.12645258671423348), (158, 0.16839988818787707), (159, 0.1857240031726577), (160, 0.15221569919704678), (161, 0.16277512828365348), (162, 0.07713789819859809), (163, 0.19288562088910888), (164, 0.18064275453849296), (165, 0.20512848723972477), (166, 0.09456723643375421), (167, 0.08801256614762654), (168, 0.2533183412394839), (169, 0.17348113682204178), (170, 0.14758163198139668), (171, 0.12545442722251762), (172, 0.18064275453849296), (173, 0.17348113682204178), (174, 0.12751055097145647), (175, 0.0646636528142584), (176, 0.09147687721269282), (177, 0.13112777786597052), (178, 0.20512848723972477), (179, 0.041795160943454514), (180, 0.06867812601598983), (181, 0.15407665275497473), (182, 0.09568241368812605), (183, 0.09320289237414721), (184, 0.1428433596105722), (185, 0.21163023716845428), (186, 0.040176367004863774), (187, 0.06190280952912888), (188, 0.16895330144111895), (189, 0.1343480729422073), (190, 0.08810601992421778), (191, 0.05411136978470962), (192, 0.07718832713384043), (193, 0.10217343791851013), (194, 0.17348113682204178), (195, 0.05055641624800683), (196, 0.10111486961133685)], [(70, 0.1509496322911158), (105, 0.13755485842037654), (197, 0.2875815034401167), (198, 0.17822786624059955), (199, 0.3793157875272854), (200, 0.5276003253191869), (201, 0.6029177073726111), (202, 0.24098183376090862)], [(203, 0.5490947594964163), (204, 0.3018565936175597), (205, 0.350260591151986), (206, 0.3249014435357001), (207, 0.4794010402625605), (208, 0.24893736516291362), (209, 0.2955316278816479)], [(23, 0.10959111430586523), (113, 0.11099248836856532), (127, 0.13607325489831845), (140, 0.10929222338395803), (143, 0.15878372886063516), (147, 0.15121364768029927), (202, 0.13559357485837867), (210, 0.1611763563170237), (211, 0.2836432736270073), (212, 0.18487109556396963), (213, 0.21354561020957816), (214, 0.15437817183678681), (215, 0.22110197096081133), (216, 0.11501021075291555), (217, 0.3650524848235283), (218, 0.1223310269301099), (219, 0.09544826782747899), (220, 0.17275505581684597), (221, 0.14377140549585818), (222, 0.1804162814086015), (223, 0.24994313515184197), (224, 0.1628922353642523), (225, 0.2739624853167774), (226, 0.23274030301843568), (227, 0.2612720705641176), (228, 0.19472627830766778), (229, 0.14662388003518012), (230, 0.14240013896124945)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'tokenized_reviews' is an iterable (e.g., list of lists)\n",
    "dictionary_bigram = corpora.Dictionary(tokenized_reviews)\n",
    "corpus_bigram = [dictionary_bigram.doc2bow(review) for review in tokenized_reviews]\n",
    "\n",
    "# Create the TF-IDF model\n",
    "tfidf_model_bigram = models.TfidfModel(corpus_bigram)\n",
    "\n",
    "# Create a list to hold all TF-IDF vectors\n",
    "all_tfidf_vectors_bigram = []\n",
    "\n",
    "# Iterate over all documents in the corpus\n",
    "for doc in corpus_bigram:\n",
    "    # Apply the TF-IDF model to get the vector for the current document\n",
    "    doc_tfidf_vector = tfidf_model[doc]\n",
    "    # Append the vector to the list\n",
    "    all_tfidf_vectors_bigram.append(doc_tfidf_vector)\n",
    "\n",
    "# Now 'all_tfidf_vectors' contains the TF-IDF vectors for all documents\n",
    "# Limit the output to the first 10 TF-IDF vectors\n",
    "limited_tfidf_vectors_bigram = all_tfidf_vectors_bigram[:10]\n",
    "\n",
    "# Now 'limited_tfidf_vectors' contains the TF-IDF vectors for the first 10 documents\n",
    "print(limited_tfidf_vectors_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4caeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'all_tfidf_vectors' is a list of TF-IDF vectors\n",
    "max_length = max(len(vector) for vector in all_tfidf_vectors_bigram)\n",
    "\n",
    "# Function to pad the vectors\n",
    "def pad_vector_bigram(vector, max_length):\n",
    "    padding = [0] * (max_length - len(vector))\n",
    "    return vector + padding\n",
    "\n",
    "# Apply padding to each vector\n",
    "padded_vectors_bigram = [pad_vector_bigram(vector, max_length) for vector in all_tfidf_vectors_bigram]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9f6034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All vectors are of the same length: 576\n",
      "[[(0, 0.15822019336594337), (1, 0.07911009668297168), (2, 0.12170821532633551), (3, 0.07493418887314095), (4, 0.11030375926386878), (5, 0.10859182482154411), (6, 0.04947903549083479), (7, 0.10374842137816317), (8, 0.1136241355227434), (9, 0.13596692814909372), (10, 0.13138885661596642), (11, 0.09599582425095556), (12, 0.1565601201334325), (13, 0.08020523861709881), (14, 0.08266694420118104), (15, 0.11723536349072858), (16, 0.18658037825369134), (17, 0.0888713835981412), (18, 0.07936684071231864), (19, 0.07183341245268707), (20, 0.12707538562583412), (21, 0.07401393015048931), (22, 0.032219935791116754), (23, 0.12179428611948441), (24, 0.05987914001758319), (25, 0.120831002481178), (26, 0.09560107520762093), (27, 0.06796589385054766), (28, 0.10209478190637414), (29, 0.11026127062439335), (30, 0.2560739659343325), (31, 0.028176078444046855), (32, 0.11693806256431222), (33, 0.1019816764207001), (34, 0.11392707128848491), (35, 0.1524549702782134), (36, 0.3968735655113111), (37, 0.10175734360716843), (38, 0.1205468458267122), (39, 0.14494580166562673), (40, 0.17899439864420652), (41, 0.11034633725911869), (42, 0.12399966044774859), (43, 0.11944849764833426), (44, 0.15867835234489372), (45, 0.11428632229866684), (46, 0.1485431044461317), (47, 0.2659537149160561), (48, 0.12847559962027527), (49, 0.09128183907513461), (50, 0.14230128775197218), (51, 0.1559351244263627), (52, 0.07034985227279414), (53, 0.12529514467356573), (54, 0.055505412590967515), (55, 0.07660234476498358), (56, 0.10170164665517933), (57, 0.058133556316320174), (58, 0.08849130632677189), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(0, 0.11416457669124039), (1, 0.057082288345620194), (2, 0.1756383504151153), (4, 0.07959023254817132), (5, 0.07835497763681423), (6, 0.07140369407635799), (8, 0.08198606674598023), (9, 0.09810762119502503), (10, 0.18960858128664884), (11, 0.06926627004171028), (14, 0.059648749570531484), (20, 0.045845941972449275), (22, 0.04649691360323611), (24, 0.021603047396522624), (25, 0.08718621786497685), (28, 0.07366700362808785), (29, 0.07955957465655392), (30, 0.43113340361148905), (31, 0.04066118236809315), (36, 0.14318305913628962), (38, 0.08698118320106354), (43, 0.08618866454603892), (44, 0.11449516360796967), (46, 0.1071820244857923), (47, 0.4477672296616153), (48, 0.09270221539850006), (51, 0.11251577369936086), (52, 0.05076128990968353), (53, 0.09040734212757148), (57, 0.04194656008957726), (59, 0.048030471594611615), (60, 0.04125404222963803), (61, 0.055342676638254575), (62, 0.05870789929889441), (63, 0.10425053064574136), (64, 0.08765834628045986), (65, 0.06361296319487746), (66, 0.09120075773748264), (67, 0.08888106172324096), (68, 0.08087250080371218), (69, 0.09379640966047523), (70, 0.03405476603602033), (71, 0.04996449255495275), (72, 0.06409368616979012), (73, 0.0955170407805), (74, 0.1461461743812108), (75, 0.054149599195664394), (76, 0.10738634222187224), (77, 0.1536085602864444), (78, 0.04682556039124491), (79, 0.2601942374819704), (80, 0.20941787593289363), (81, 0.15113035449017623), (82, 0.03143056760768222), (83, 0.07228210868878054), (84, 0.07734709665396505), (85, 0.06703817110006498), (86, 0.06425392704512127), (87, 0.08367058294033307), (88, 0.12698023221598426), (89, 0.12323108012601793), (90, 0.047019053021239245), (91, 0.08899746457015016), (92, 0.10139468938281304), (93, 0.09347533124138291), (94, 0.04212494348851259), (95, 0.03228047043631043), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(22, 0.059435528639504104), (31, 0.05197589865377), (47, 0.16353332444188057), (53, 0.23112967101845402), (61, 0.14148557344635723), (66, 0.23315806699364935), (71, 0.1277360494741096), (96, 0.16753711121382117), (97, 0.19727257776792978), (98, 0.13869761031581512), (99, 0.26028130020535134), (100, 0.33794243734996116), (101, 0.17620205218625346), (102, 0.1581279374627826), (103, 0.14563163126522014), (104, 0.26652028789486004), (105, 0.07933663480085813), (106, 0.1962888392659639), (107, 0.19890252861837474), (108, 0.15938361993832514), (109, 0.18280014949331955), (110, 0.33259803404708693), (111, 0.09722253555362718), (112, 0.3257888503586839), (113, 0.056886161162777525), (114, 0.11680398930026273), (115, 0.14192080692811235), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(57, 0.14714870634845528), (105, 0.10886339464803592), (115, 0.19473955319838818), (116, 0.5241167345705715), (117, 0.46312326779036983), (118, 0.2147881412031032), (119, 0.26934176660823517), (120, 0.12337660264907935), (121, 0.12296654558415389), (122, 0.5388594650414585), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(3, 0.232654913903139), (113, 0.09574528300880353), (123, 0.28223500802093854), (124, 0.4060912910436275), (125, 0.4769925179797686), (126, 0.29322123326761207), (127, 0.23476133370226132), (128, 0.5687920162545391), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(70, 0.10139706025857939), (129, 0.18392019026419607), (130, 0.16359835555657576), (131, 0.1951919848113645), (132, 0.13788735301426827), (133, 0.11962204628105651), (134, 0.10473082480338733), (135, 0.15795967604798405), (136, 0.27277867311113235), (137, 0.1645904498555037), (138, 0.1631441257157089), (139, 0.19964288987582682), (140, 0.13047513642393369), (141, 0.21940228987999869), (142, 0.14351792159564555), (143, 0.3791180752579176), (144, 0.22838224896242873), (145, 0.5051505415496846), (146, 0.29051909515877405), (147, 0.18052173063526142), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(6, 0.043166148684837584), (12, 0.13658506793342023), (19, 0.06266839544692261), (28, 0.17813760886802033), (78, 0.05661553308258239), (148, 0.13500232264754844), (149, 0.09899648696849205), (150, 0.14391415548664527), (151, 0.1707584161302298), (152, 0.0671406183730905), (153, 0.18064275453849296), (154, 0.15615702183726118), (155, 0.09645447660395232), (156, 0.10486155973036489), (157, 0.12645258671423348), (158, 0.16839988818787707), (159, 0.1857240031726577), (160, 0.15221569919704678), (161, 0.16277512828365348), (162, 0.07713789819859809), (163, 0.19288562088910888), (164, 0.18064275453849296), (165, 0.20512848723972477), (166, 0.09456723643375421), (167, 0.08801256614762654), (168, 0.2533183412394839), (169, 0.17348113682204178), (170, 0.14758163198139668), (171, 0.12545442722251762), (172, 0.18064275453849296), (173, 0.17348113682204178), (174, 0.12751055097145647), (175, 0.0646636528142584), (176, 0.09147687721269282), (177, 0.13112777786597052), (178, 0.20512848723972477), (179, 0.041795160943454514), (180, 0.06867812601598983), (181, 0.15407665275497473), (182, 0.09568241368812605), (183, 0.09320289237414721), (184, 0.1428433596105722), (185, 0.21163023716845428), (186, 0.040176367004863774), (187, 0.06190280952912888), (188, 0.16895330144111895), (189, 0.1343480729422073), (190, 0.08810601992421778), (191, 0.05411136978470962), (192, 0.07718832713384043), (193, 0.10217343791851013), (194, 0.17348113682204178), (195, 0.05055641624800683), (196, 0.10111486961133685), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(70, 0.1509496322911158), (105, 0.13755485842037654), (197, 0.2875815034401167), (198, 0.17822786624059955), (199, 0.3793157875272854), (200, 0.5276003253191869), (201, 0.6029177073726111), (202, 0.24098183376090862), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(203, 0.5490947594964163), (204, 0.3018565936175597), (205, 0.350260591151986), (206, 0.3249014435357001), (207, 0.4794010402625605), (208, 0.24893736516291362), (209, 0.2955316278816479), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [(23, 0.10959111430586523), (113, 0.11099248836856532), (127, 0.13607325489831845), (140, 0.10929222338395803), (143, 0.15878372886063516), (147, 0.15121364768029927), (202, 0.13559357485837867), (210, 0.1611763563170237), (211, 0.2836432736270073), (212, 0.18487109556396963), (213, 0.21354561020957816), (214, 0.15437817183678681), (215, 0.22110197096081133), (216, 0.11501021075291555), (217, 0.3650524848235283), (218, 0.1223310269301099), (219, 0.09544826782747899), (220, 0.17275505581684597), (221, 0.14377140549585818), (222, 0.1804162814086015), (223, 0.24994313515184197), (224, 0.1628922353642523), (225, 0.2739624853167774), (226, 0.23274030301843568), (227, 0.2612720705641176), (228, 0.19472627830766778), (229, 0.14662388003518012), (230, 0.14240013896124945), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'padded_vectors' is a list of lists (vectors)\n",
    "vector_lengths = [len(vector) for vector in padded_vectors_bigram]\n",
    "\n",
    "# Check if all vectors are of the same length\n",
    "if len(set(vector_lengths)) == 1:\n",
    "    print(\"All vectors are of the same length:\", vector_lengths[0])\n",
    "else:\n",
    "    print(\"Vectors are of varying lengths\")\n",
    "limited_padded_vectors_bigram = padded_vectors_bigram[:10]\n",
    "\n",
    "# Now 'limited_tfidf_vectors' contains the TF-IDF vectors for the first 10 documents\n",
    "print(limited_padded_vectors_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de00d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the TF-IDF matrix\n",
    "normalized_tfidf_matrix_sparse_bigram = normalize(tfidf_matrix_sparse_bigram)\n",
    "\n",
    "# Initialize Truncated SVD with desired number of components\n",
    "n_components = 100  # Adjust the number of components as needed\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "\n",
    "# Apply Truncated SVD to the normalized TF-IDF matrix\n",
    "tfidf_matrix_reduced_bigram = svd.fit_transform(normalized_tfidf_matrix_sparse_bigram)\n",
    "\n",
    "# Define a function to calculate cosine similarity in chunks\n",
    "def chunk_similarity(matrix, ref_idx, chunk_size=1000):\n",
    "    num_chunks = matrix.shape[0] // chunk_size + (1 if matrix.shape[0] % chunk_size != 0 else 0)\n",
    "    sim_scores = []\n",
    "\n",
    "    for chunk_start in range(0, matrix.shape[0], chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, matrix.shape[0])\n",
    "        sim_chunk = cosine_similarity(matrix[ref_idx:ref_idx+1], matrix[chunk_start:chunk_end])\n",
    "        sim_scores.extend(sim_chunk.flatten())\n",
    "\n",
    "    return sim_scores\n",
    "\n",
    "# Get recommendations based on cosine similarity matrix in chunks\n",
    "def get_recommendations_in_chunks(product_index, matrix, n=5, threshold=0.2, chunk_size=1000):\n",
    "    num_docs = matrix.shape[0]\n",
    "    sim_scores = np.zeros(num_docs)\n",
    "\n",
    "    for chunk_start in range(0, num_docs, chunk_size):\n",
    "        chunk_end = min(chunk_start + chunk_size, num_docs)\n",
    "        sim_chunk = cosine_similarity(matrix[product_index:product_index+1], matrix[chunk_start:chunk_end])\n",
    "        sim_scores[chunk_start:chunk_end] = sim_chunk.flatten()\n",
    "\n",
    "    # Filter out low similarity scores based on threshold\n",
    "    sim_indices = [(idx, score) for idx, score in enumerate(sim_scores) if score > threshold]\n",
    "    # Sort the products based on similarity scores\n",
    "    sim_indices = sorted(sim_indices, key=lambda x: x[1], reverse=True)\n",
    "    # Get the top similar products\n",
    "    top_similar_products_bigram = sim_indices[:n]  # Limit to top N\n",
    "    return top_similar_products_bigram\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85477b27",
   "metadata": {},
   "source": [
    "### Getting Recommendations for Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ff31ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended products:\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n",
      "|                                                                                                       Title                                                                                                        | Price | Avg Rating | Cosine Similarity Score |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n",
      "|                                                                                    planters peanuts unsalted dry roasted 16 oz                                                                                     | 41.99 |    4.5     |           1.0           |\n",
      "|                                                          kinder joy eggs cream chocolatey wafers toy inside105 oz bulk 1 pack packaging may vary 15 eggs                                                           | 29.85 |    4.7     |           1.0           |\n",
      "| bees knees raw honeycomb 100 edible allnatural gourmet honeycomb double sealed packaging 7 oz acacia honey comb sweet light flavor gluten free paleo friendly foodie gifts charcuterie tea gifts unique gift ideas | 14.99 |    4.1     |   0.8551123609643858    |\n",
      "|                                                                       amazon brand happy belly cinnamon rolls original icing 8 ct 124 ounce                                                                        | 2.99  |    4.5     |   0.8141939161107432    |\n",
      "|                                                                     goetzes candy vanilla cow tales minis 2 pound bag 32 ounces fresh factory                                                                      | 19.95 |    4.7     |   0.8060754061218258    |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+------------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "product_index = 45\n",
    "top_similar_products_bigram = get_recommendations_in_chunks(product_index, tfidf_matrix_reduced_bigram)\n",
    "\n",
    "# Prepare the data for tabular display\n",
    "table_data = []\n",
    "for index, score in top_similar_products_bigram:\n",
    "    title = df.iloc[index]['title_x']\n",
    "    price = df.iloc[index]['price']\n",
    "    avg_rating = df.iloc[index]['average_rating']\n",
    "    table_data.append([title, price, avg_rating, score])\n",
    "\n",
    "# Display the recommendations in a tabular format\n",
    "print(\"Top 5 recommended products:\")\n",
    "print(tabulate(table_data, headers=['Title', 'Price', 'Avg Rating', 'Cosine Similarity Score'], tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771a9a8",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "869bc52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.9807542734697822\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming get_recommendations_in_chunks is defined and returns a list of tuples (index, score)\n",
    "product_index = 0\n",
    "top_similar_products_bigram = get_recommendations_in_chunks(product_index, tfidf_matrix_reduced_bigram)\n",
    "\n",
    "# Extract the indices and scores from the recommendations\n",
    "top_indices = [index for index, score in top_similar_products_bigram]\n",
    "top_scores = [score for index, score in top_similar_products_bigram]\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'average_rating' is a column in your dataset\n",
    "# Prepare relevance scores based on the average_rating of the recommended products\n",
    "relevance_scores = df.loc[top_indices, 'average_rating'].tolist()\n",
    "\n",
    "# Normalize relevance scores since NDCG in sklearn assumes relevance scores, not ratings directly\n",
    "max_rating = max(relevance_scores)\n",
    "normalized_relevance_scores = [score / max_rating for score in relevance_scores]\n",
    "\n",
    "# Reshape for ndcg_score function\n",
    "true_relevance = np.asarray([normalized_relevance_scores])\n",
    "predicted_relevance = np.asarray([top_scores])\n",
    "\n",
    "# Calculate NDCG score\n",
    "ndcg = ndcg_score(true_relevance, predicted_relevance)\n",
    "print(\"NDCG Score:\", ndcg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d39df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
